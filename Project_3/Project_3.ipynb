{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Project 3 Web APIs & Classification\n",
    "_Authors: Li Jiansheng\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "As a data scientist in Android Inc, we are looking at how to better design and develop android phones. There are many variants of Android and we want to look at reddit forums to see what users prefer in a mobile phone. At the same time, Android has a close competitor, Iphone. <br><br>We would also want to look at their users comments on Iphone as well. However as there are still differences in the phones' users and usage, we would want to classify the two types of reddit posts to enhance our research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executive Summary\n",
    "\n",
    "### Contents:\n",
    "- [Android Posts Data Import](reddit-android-data-collection.ipynb)\n",
    "- [Iphone Posts Data Import](reddit-iphone-data-collection.ipynb)\n",
    "- [Exploratory Data Analysis](#Exploratory-Data-Analysis)\n",
    "- [Modeling](#Modeling)\n",
    "- [Model Evaluation](#Model-Evaluation)\n",
    "- [Conclusion and Recommendations](#Conclusion-and-Recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping\n",
    "We start our project by scraping data from our topics of interest, Android and Iphone. Web scraping from 2 reddit topics were done in another file. \n",
    "- [Android Posts Data Import](reddit-android-data-collection.ipynb)\n",
    "- [Iphone Posts Data Import](reddit-iphone-data-collection.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All libraries used in this project are listed here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import re\n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV,cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import roc_auc_score, make_scorer, recall_score, precision_score,accuracy_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read scrapped data into Dataframes\n",
    "We saved our scrapped in 2 different csv files. We want to read the data into dataframes for exploratory data analysis and cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "786"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "android_df = pd.read_csv('./datasets/android.csv')\n",
    "\n",
    "android_df.drop_duplicates(subset='title', keep='first', inplace=True)\n",
    "len(android_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "715"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iphone_df = pd.read_csv('./datasets/iphone.csv')\n",
    "iphone_df.drop_duplicates(subset='title', keep='first', inplace=True)\n",
    "len(iphone_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>approved_at_utc</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>author_fullname</th>\n",
       "      <th>saved</th>\n",
       "      <th>mod_reason_title</th>\n",
       "      <th>gilded</th>\n",
       "      <th>clicked</th>\n",
       "      <th>title</th>\n",
       "      <th>link_flair_richtext</th>\n",
       "      <th>...</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>num_crossposts</th>\n",
       "      <th>media</th>\n",
       "      <th>is_video</th>\n",
       "      <th>post_hint</th>\n",
       "      <th>preview</th>\n",
       "      <th>crosspost_parent_list</th>\n",
       "      <th>crosspost_parent</th>\n",
       "      <th>link_flair_template_id</th>\n",
       "      <th>author_cakeday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Android</td>\n",
       "      <td>Note 1. Join us at /r/MoronicMondayAndroid, a ...</td>\n",
       "      <td>t2_6l4z3</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Moronic Monday (Jan 20 2020) - Your weekly que...</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>1.579519e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Android</td>\n",
       "      <td>Device reviews are everywhere these days. From...</td>\n",
       "      <td>t2_p7o61</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/android reviews: LG line</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>1.579374e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Android</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t2_kfy6p</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Samsung Galaxy S20 release in France (and worl...</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>1.579615e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>link</td>\n",
       "      <td>{'images': [{'source': {'url': 'https://extern...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Android</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t2_2ja6dymo</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Good Lock 2020 with Android 10 support will be...</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>1.579623e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>link</td>\n",
       "      <td>{'images': [{'source': {'url': 'https://extern...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Android</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t2_tamwpg9</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Wine 5.0 Released - run some Windows programs ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>1.579636e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>link</td>\n",
       "      <td>{'images': [{'source': {'url': 'https://extern...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   approved_at_utc subreddit  \\\n",
       "0              NaN   Android   \n",
       "1              NaN   Android   \n",
       "2              NaN   Android   \n",
       "3              NaN   Android   \n",
       "4              NaN   Android   \n",
       "\n",
       "                                            selftext author_fullname  saved  \\\n",
       "0  Note 1. Join us at /r/MoronicMondayAndroid, a ...        t2_6l4z3  False   \n",
       "1  Device reviews are everywhere these days. From...        t2_p7o61  False   \n",
       "2                                                NaN        t2_kfy6p  False   \n",
       "3                                                NaN     t2_2ja6dymo  False   \n",
       "4                                                NaN      t2_tamwpg9  False   \n",
       "\n",
       "   mod_reason_title  gilded  clicked  \\\n",
       "0               NaN       0    False   \n",
       "1               NaN       0    False   \n",
       "2               NaN       0    False   \n",
       "3               NaN       0    False   \n",
       "4               NaN       0    False   \n",
       "\n",
       "                                               title link_flair_richtext  ...  \\\n",
       "0  Moronic Monday (Jan 20 2020) - Your weekly que...                  []  ...   \n",
       "1                        /r/android reviews: LG line                  []  ...   \n",
       "2  Samsung Galaxy S20 release in France (and worl...                  []  ...   \n",
       "3  Good Lock 2020 with Android 10 support will be...                  []  ...   \n",
       "4  Wine 5.0 Released - run some Windows programs ...                  []  ...   \n",
       "\n",
       "    created_utc  num_crossposts  media is_video  post_hint  \\\n",
       "0  1.579519e+09               0    NaN    False        NaN   \n",
       "1  1.579374e+09               0    NaN    False        NaN   \n",
       "2  1.579615e+09               0    NaN    False       link   \n",
       "3  1.579623e+09               0    NaN    False       link   \n",
       "4  1.579636e+09               0    NaN    False       link   \n",
       "\n",
       "                                             preview  crosspost_parent_list  \\\n",
       "0                                                NaN                    NaN   \n",
       "1                                                NaN                    NaN   \n",
       "2  {'images': [{'source': {'url': 'https://extern...                    NaN   \n",
       "3  {'images': [{'source': {'url': 'https://extern...                    NaN   \n",
       "4  {'images': [{'source': {'url': 'https://extern...                    NaN   \n",
       "\n",
       "  crosspost_parent  link_flair_template_id author_cakeday  \n",
       "0              NaN                     NaN            NaN  \n",
       "1              NaN                     NaN            NaN  \n",
       "2              NaN                     NaN            NaN  \n",
       "3              NaN                     NaN            NaN  \n",
       "4              NaN                     NaN            NaN  \n",
       "\n",
       "[5 rows x 107 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "android_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>approved_at_utc</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>author_fullname</th>\n",
       "      <th>saved</th>\n",
       "      <th>mod_reason_title</th>\n",
       "      <th>gilded</th>\n",
       "      <th>clicked</th>\n",
       "      <th>title</th>\n",
       "      <th>link_flair_richtext</th>\n",
       "      <th>...</th>\n",
       "      <th>num_crossposts</th>\n",
       "      <th>media</th>\n",
       "      <th>is_video</th>\n",
       "      <th>post_hint</th>\n",
       "      <th>preview</th>\n",
       "      <th>crosspost_parent_list</th>\n",
       "      <th>crosspost_parent</th>\n",
       "      <th>link_flair_template_id</th>\n",
       "      <th>media_metadata</th>\n",
       "      <th>author_cakeday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>iphone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t2_s0id44</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Why isnâ€™t iCloud storage offered in size incre...</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>iphone</td>\n",
       "      <td>Does automatic brightness adjustment use more ...</td>\n",
       "      <td>t2_21lzgjf2</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Brightness adjustment.</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>iphone</td>\n",
       "      <td>I was wondering if Apple ever discloses what i...</td>\n",
       "      <td>t2_2ok9v9e</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Most popular iPhone colors</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>iphone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t2_17u3sw1m</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>My brand-new iPhone just got a crack on the fr...</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>iphone</td>\n",
       "      <td>\\nHey guys,\\nI made the jump to the 11 Pro Max...</td>\n",
       "      <td>t2_1fzkarcp</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>I bought a 11 Pro Max after reading what you g...</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   approved_at_utc subreddit  \\\n",
       "0              NaN    iphone   \n",
       "1              NaN    iphone   \n",
       "2              NaN    iphone   \n",
       "3              NaN    iphone   \n",
       "4              NaN    iphone   \n",
       "\n",
       "                                            selftext author_fullname  saved  \\\n",
       "0                                                NaN       t2_s0id44  False   \n",
       "1  Does automatic brightness adjustment use more ...     t2_21lzgjf2  False   \n",
       "2  I was wondering if Apple ever discloses what i...      t2_2ok9v9e  False   \n",
       "3                                                NaN     t2_17u3sw1m  False   \n",
       "4  \\nHey guys,\\nI made the jump to the 11 Pro Max...     t2_1fzkarcp  False   \n",
       "\n",
       "   mod_reason_title  gilded  clicked  \\\n",
       "0               NaN       0    False   \n",
       "1               NaN       0    False   \n",
       "2               NaN       0    False   \n",
       "3               NaN       0    False   \n",
       "4               NaN       0    False   \n",
       "\n",
       "                                               title link_flair_richtext  ...  \\\n",
       "0  Why isnâ€™t iCloud storage offered in size incre...                  []  ...   \n",
       "1                             Brightness adjustment.                  []  ...   \n",
       "2                         Most popular iPhone colors                  []  ...   \n",
       "3  My brand-new iPhone just got a crack on the fr...                  []  ...   \n",
       "4  I bought a 11 Pro Max after reading what you g...                  []  ...   \n",
       "\n",
       "  num_crossposts  media  is_video post_hint  preview  crosspost_parent_list  \\\n",
       "0              0    NaN     False       NaN      NaN                    NaN   \n",
       "1              0    NaN     False       NaN      NaN                    NaN   \n",
       "2              0    NaN     False       NaN      NaN                    NaN   \n",
       "3              0    NaN     False       NaN      NaN                    NaN   \n",
       "4              0    NaN     False       NaN      NaN                    NaN   \n",
       "\n",
       "   crosspost_parent link_flair_template_id  media_metadata author_cakeday  \n",
       "0               NaN                    NaN             NaN            NaN  \n",
       "1               NaN                    NaN             NaN            NaN  \n",
       "2               NaN                    NaN             NaN            NaN  \n",
       "3               NaN                    NaN             NaN            NaN  \n",
       "4               NaN                    NaN             NaN            NaN  \n",
       "\n",
       "[5 rows x 108 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iphone_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to analyse text from columns selftext and title as our main text source. **Subreddit** will be our classification target. We will combine the 2 dataframes first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine Android and Iphone dataframes\n",
    "Check for null after combining. We will fill any null with none data as there is no where to enter correct data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/DSI/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mobile_df = pd.concat([android_df,iphone_df])\n",
    "\n",
    "#check for na in 'title' and 'selftext'\n",
    "mobile_df['title'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "749"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mobile_df['selftext'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobile_df['selftext'].fillna('', inplace=True)\n",
    "\n",
    "mobile_df['content']=mobile_df['title'] +' '+ mobile_df['selftext']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map Subreddit\n",
    "Android will be our positive value posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_awardings</th>\n",
       "      <th>allow_live_comments</th>\n",
       "      <th>approved_at_utc</th>\n",
       "      <th>approved_by</th>\n",
       "      <th>archived</th>\n",
       "      <th>author</th>\n",
       "      <th>author_cakeday</th>\n",
       "      <th>author_flair_background_color</th>\n",
       "      <th>author_flair_css_class</th>\n",
       "      <th>author_flair_richtext</th>\n",
       "      <th>...</th>\n",
       "      <th>title</th>\n",
       "      <th>total_awards_received</th>\n",
       "      <th>ups</th>\n",
       "      <th>url</th>\n",
       "      <th>user_reports</th>\n",
       "      <th>view_count</th>\n",
       "      <th>visited</th>\n",
       "      <th>whitelist_status</th>\n",
       "      <th>wls</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>AutoModerator</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>robot</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>Moronic Monday (Jan 20 2020) - Your weekly que...</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>https://www.reddit.com/r/Android/comments/erby...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>6</td>\n",
       "      <td>Moronic Monday (Jan 20 2020) - Your weekly que...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>curated_android</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>/r/android reviews: LG line</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>https://www.reddit.com/r/Android/comments/eqki...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>6</td>\n",
       "      <td>/r/android reviews: LG line Device reviews are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>CliveLH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>Samsung Galaxy S20 release in France (and worl...</td>\n",
       "      <td>0</td>\n",
       "      <td>1219</td>\n",
       "      <td>https://www.frandroid.com/marques/samsung/6615...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>6</td>\n",
       "      <td>Samsung Galaxy S20 release in France (and worl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>ihjao</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>Good Lock 2020 with Android 10 support will be...</td>\n",
       "      <td>0</td>\n",
       "      <td>680</td>\n",
       "      <td>https://www.sammobile.com/news/good-lock-2020-...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>6</td>\n",
       "      <td>Good Lock 2020 with Android 10 support will be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>merrycachemiss</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>Wine 5.0 Released - run some Windows programs ...</td>\n",
       "      <td>0</td>\n",
       "      <td>340</td>\n",
       "      <td>https://www.winehq.org/news/2020012101</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>6</td>\n",
       "      <td>Wine 5.0 Released - run some Windows programs ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 109 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  all_awardings  allow_live_comments  approved_at_utc  approved_by  archived  \\\n",
       "0            []                False              NaN          NaN     False   \n",
       "1            []                False              NaN          NaN     False   \n",
       "2            []                False              NaN          NaN     False   \n",
       "3            []                 True              NaN          NaN     False   \n",
       "4            []                False              NaN          NaN     False   \n",
       "\n",
       "            author author_cakeday author_flair_background_color  \\\n",
       "0    AutoModerator            NaN                           NaN   \n",
       "1  curated_android            NaN                           NaN   \n",
       "2          CliveLH            NaN                           NaN   \n",
       "3            ihjao            NaN                           NaN   \n",
       "4   merrycachemiss            NaN                           NaN   \n",
       "\n",
       "  author_flair_css_class author_flair_richtext  ...  \\\n",
       "0                  robot                    []  ...   \n",
       "1                    NaN                    []  ...   \n",
       "2                    NaN                    []  ...   \n",
       "3                    NaN                    []  ...   \n",
       "4                    NaN                    []  ...   \n",
       "\n",
       "                                               title total_awards_received  \\\n",
       "0  Moronic Monday (Jan 20 2020) - Your weekly que...                     0   \n",
       "1                        /r/android reviews: LG line                     0   \n",
       "2  Samsung Galaxy S20 release in France (and worl...                     0   \n",
       "3  Good Lock 2020 with Android 10 support will be...                     0   \n",
       "4  Wine 5.0 Released - run some Windows programs ...                     0   \n",
       "\n",
       "    ups                                                url user_reports  \\\n",
       "0    15  https://www.reddit.com/r/Android/comments/erby...           []   \n",
       "1    86  https://www.reddit.com/r/Android/comments/eqki...           []   \n",
       "2  1219  https://www.frandroid.com/marques/samsung/6615...           []   \n",
       "3   680  https://www.sammobile.com/news/good-lock-2020-...           []   \n",
       "4   340             https://www.winehq.org/news/2020012101           []   \n",
       "\n",
       "  view_count visited whitelist_status  wls  \\\n",
       "0        NaN   False          all_ads    6   \n",
       "1        NaN   False          all_ads    6   \n",
       "2        NaN   False          all_ads    6   \n",
       "3        NaN   False          all_ads    6   \n",
       "4        NaN   False          all_ads    6   \n",
       "\n",
       "                                             content  \n",
       "0  Moronic Monday (Jan 20 2020) - Your weekly que...  \n",
       "1  /r/android reviews: LG line Device reviews are...  \n",
       "2  Samsung Galaxy S20 release in France (and worl...  \n",
       "3  Good Lock 2020 with Android 10 support will be...  \n",
       "4  Wine 5.0 Released - run some Windows programs ...  \n",
       "\n",
       "[5 rows x 109 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mobile_df['subreddit'] = mobile_df['subreddit'].map({'Android':1,'iphone':0})\n",
    "mobile_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "710    0\n",
       "711    0\n",
       "712    0\n",
       "713    0\n",
       "714    0\n",
       "Name: subreddit, Length: 1501, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mobile_df['subreddit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.523651\n",
       "0    0.476349\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mobile_df['subreddit'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Dataframe\n",
    "After combining and removing unwanted columns, we have our final dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Moronic Monday (Jan 20 2020) - Your weekly que...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>/r/android reviews: LG line Device reviews are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Samsung Galaxy S20 release in France (and worl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Good Lock 2020 with Android 10 support will be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Wine 5.0 Released - run some Windows programs ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subreddit                                            content\n",
       "0          1  Moronic Monday (Jan 20 2020) - Your weekly que...\n",
       "1          1  /r/android reviews: LG line Device reviews are...\n",
       "2          1  Samsung Galaxy S20 release in France (and worl...\n",
       "3          1  Good Lock 2020 with Android 10 support will be...\n",
       "4          1  Wine 5.0 Released - run some Windows programs ..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mobile_df=mobile_df.loc[:,('subreddit','content')]\n",
    "mobile_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply lowercase to all content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobile_df['content']=[c.lower() for c in mobile_df['content']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>moronic monday (jan 20 2020) - your weekly que...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>/r/android reviews: lg line device reviews are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>samsung galaxy s20 release in france (and worl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>good lock 2020 with android 10 support will be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>wine 5.0 released - run some windows programs ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subreddit                                            content\n",
       "0          1  moronic monday (jan 20 2020) - your weekly que...\n",
       "1          1  /r/android reviews: lg line device reviews are...\n",
       "2          1  samsung galaxy s20 release in france (and worl...\n",
       "3          1  good lock 2020 with android 10 support will be...\n",
       "4          1  wine 5.0 released - run some windows programs ..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mobile_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Test Split the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(mobile_df[['content']],\n",
    "                                                    mobile_df['subreddit'],\n",
    "                                                    test_size = 0.25,\n",
    "                                                    stratify=mobile_df['subreddit'],\n",
    "                                                    random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1125, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_to_words(raw_content):\n",
    "    # Function to convert a raw review to a string of words\n",
    "    # The input is a single string (a raw movie review), and \n",
    "    # the output is a single string (a preprocessed movie review)\n",
    "    \n",
    "    # 1. Remove HTML.\n",
    "    content_text = BeautifulSoup(raw_content).get_text()\n",
    "    \n",
    "    # 2. Remove non-letters.\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", content_text)\n",
    "    \n",
    "    # 3. Convert to lower case, split into individual words.\n",
    "    words = letters_only.lower().split()\n",
    "    \n",
    "    # 4. In Python, searching a set is much faster than searching\n",
    "    # a list, so convert the stop words to a set.\n",
    "    stops = stopwords.words('english')\n",
    "    stops.extend(['none','iphone','android','mobile','device','app','ios','\\n', 'www', 'reddit', 'com', 'comment', 'http','https'])\n",
    "    stops = set(stops)\n",
    "  \n",
    "    # 5. Remove stop words.\n",
    "    meaningful_words = [w for w in words if not w in stops]\n",
    "    # 6. Lemmatize our words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens_lem = [lemmatizer.lemmatize(i) for i in meaningful_words]\n",
    "    \n",
    "    # 7. Join the words back into one string separated by space, \n",
    "    # and return the result.\n",
    "    return(\" \".join(tokens_lem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1501 content.\n"
     ]
    }
   ],
   "source": [
    "# Get the number of posts based on the dataframe size.\n",
    "total_content = mobile_df.shape[0]\n",
    "print(f'There are {total_content} content.')\n",
    "\n",
    "# Initialize an empty list to hold the clean posts.\n",
    "clean_train_content = []\n",
    "clean_test_content = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing the training set content...\n",
      "Cleaning and parsing the testing set content...\n"
     ]
    }
   ],
   "source": [
    "print(\"Cleaning and parsing the training set content...\")\n",
    "\n",
    "j = 0\n",
    "for train_content in X_train['content']:\n",
    "    # Convert posts to words, then append to clean_train_content.\n",
    "    clean_train_content.append(review_to_words(train_content))\n",
    "    \n",
    "print(\"Cleaning and parsing the testing set content...\")\n",
    "\n",
    "for test_content in X_test['content']:\n",
    "    # Convert posts to words, then append to clean_train_content.\n",
    "    clean_test_content.append(review_to_words(test_content))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "The 2 models we will be using will be Logistic Regression and Naive Bayes Mutlinomial. As our content will be converted to integers using CountVectorizer, Multinomial will be chosen. The way we implement our models will be through pipeline. This method is easier to implement and allows a easier way to implement GridSearch as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i) Logistic Regression Model with CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('cvec', CountVectorizer()),\n",
    "                 ('lr', LogisticRegression(solver='lbfgs'))\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.85840708, 0.89333333, 0.83111111, 0.85333333, 0.875     ])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(pipe, clean_train_content, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9946666666666667\n",
      "0.8351063829787234\n"
     ]
    }
   ],
   "source": [
    "# ii. Fit into model\n",
    "pipe.fit(clean_train_content, y_train)\n",
    "\n",
    "# Training score\n",
    "print(pipe.score(clean_train_content, y_train))\n",
    "\n",
    "# Test score\n",
    "print(pipe.score(clean_test_content, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_params = {\n",
    "    'cvec__max_features': [2500, 3000, 3500],\n",
    "    'cvec__min_df': [1, 2],\n",
    "    'cvec__max_df': [.8,.9, .95],\n",
    "    'cvec__ngram_range': [(1,1), (1,2)]\n",
    "}\n",
    "scorers = {\n",
    "    'precision_score': make_scorer(precision_score),\n",
    "    'recall_score': make_scorer(recall_score),\n",
    "    'accuracy_score': make_scorer(accuracy_score)\n",
    "}\n",
    "#scorers dictionary allows us to prioritize which score we want for the model. Then we refit back the parameters to our model\n",
    "gs = GridSearchCV(pipe,param_grid=pipe_params,scoring=scorers,refit='accuracy_score', cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 Âµs, sys: 1 Âµs, total: 5 Âµs\n",
      "Wall time: 8.11 Âµs\n",
      "0.8684444444444445\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.8,\n",
       " 'cvec__max_features': 3500,\n",
       " 'cvec__min_df': 1,\n",
       " 'cvec__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time \n",
    "gs.fit(clean_train_content, y_train)\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9911111111111112"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(clean_train_content, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8430851063829787"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(clean_test_content, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii) Logistic Regression Model with TFIDVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe2 = Pipeline([('tfid', TfidfVectorizer()),\n",
    "                 ('lr', LogisticRegression(solver='lbfgs'))\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.86283186, 0.91555556, 0.83111111, 0.87111111, 0.875     ])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(pipe2, clean_train_content, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9697777777777777\n",
      "0.8377659574468085\n"
     ]
    }
   ],
   "source": [
    "# ii. Fit into model\n",
    "pipe2.fit(clean_train_content, y_train)\n",
    "\n",
    "# Training score\n",
    "print(pipe2.score(clean_train_content, y_train))\n",
    "\n",
    "# Test score\n",
    "print(pipe2.score(clean_test_content, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe2_params = {\n",
    "    'tfid__max_features': [2500, 3000, 3500],\n",
    "    'tfid__min_df': [1, 2],\n",
    "    'tfid__max_df': [.8,.9, .95],\n",
    "    'tfid__ngram_range': [(1,1), (1,2)]\n",
    "}\n",
    "\n",
    "\n",
    "gs_lr1 = GridSearchCV(pipe2,param_grid=pipe2_params,scoring=scorers,refit='accuracy_score', cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8 Âµs, sys: 1e+03 ns, total: 9 Âµs\n",
      "Wall time: 5.01 Âµs\n"
     ]
    }
   ],
   "source": [
    "%time \n",
    "gs_lr1.fit(clean_train_content, y_train)\n",
    "print(gs_lr1.best_score_)\n",
    "gs_lr1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gs_lr1.score(clean_train_content, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gs_lr1.score(clean_test_content, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iii) View Logistic Regression stats using confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Confusion matrix with CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_predictions=gs.predict(clean_test_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_cm=confusion_matrix(y_test, lr_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_cm_df = pd.DataFrame(lr_cm, columns=['pred Iphone', 'pred Android'], index=['actual Iphone', 'actual Android'])\n",
    "lr_cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, lr_predictions).ravel()\n",
    "print(\"True Negatives: %s\" % tn)\n",
    "print(\"False Positives: %s\" % fp)\n",
    "print(\"False Negatives: %s\" % fn)\n",
    "print(\"True Positives: %s\" % tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Confusion matrix with TFIDVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr1_predictions=gs_lr1.predict(clean_test_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr1_cm=confusion_matrix(y_test, lr1_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr1_cm_df = pd.DataFrame(lr1_cm, columns=['pred Iphone', 'pred Android'], index=['actual Iphone', 'actual Android'])\n",
    "lr1_cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, lr1_predictions).ravel()\n",
    "print(\"True Negatives: %s\" % tn)\n",
    "print(\"False Positives: %s\" % fp)\n",
    "print(\"False Negatives: %s\" % fn)\n",
    "print(\"True Positives: %s\" % tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iv) Naive Bayes Multinomial with CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe3 = Pipeline([('cvec', CountVectorizer()),\n",
    "                 ('nb', MultinomialNB())\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(pipe3, clean_train_content, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ii. Fit into model\n",
    "pipe3.fit(clean_train_content, y_train)\n",
    "\n",
    "# Training score\n",
    "print(pipe3.score(clean_train_content, y_train))\n",
    "\n",
    "# Test score\n",
    "print(pipe3.score(clean_test_content, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_params3 = {\n",
    "    'cvec__max_features': [2500, 3000, 3500],\n",
    "    'cvec__min_df': [1, 2],\n",
    "    'cvec__max_df': [.8,.9, .95],\n",
    "    'cvec__ngram_range': [(1,1), (1,2)]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_nb1 = GridSearchCV(pipe3, param_grid=pipe_params3,scoring=scorers,refit='accuracy_score', cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time \n",
    "gs_nb1.fit(clean_train_content, y_train)\n",
    "print(gs_nb1.best_score_)\n",
    "gs_nb1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_nb1.score(clean_train_content,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_nb1.score(clean_test_content,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### v) Naive Bayes Multinomial with TFIDVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe4 = Pipeline([('tfid', TfidfVectorizer()),\n",
    "                 ('nb', MultinomialNB())\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(pipe4, clean_train_content, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ii. Fit into model\n",
    "pipe4.fit(clean_train_content, y_train)\n",
    "\n",
    "# Training score\n",
    "print(pipe4.score(clean_train_content, y_train))\n",
    "\n",
    "# Test score\n",
    "print(pipe4.score(clean_test_content, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_params4 = {\n",
    "    'tfid__max_features': [2500, 3000, 3500],\n",
    "    'tfid__min_df': [1, 2],\n",
    "    'tfid__max_df': [.8,.9, .95],\n",
    "    'tfid__ngram_range': [(1,1), (1,2)]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_nb2 = GridSearchCV(pipe4, param_grid=pipe_params4,scoring=scorers,refit='accuracy_score', cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%time \n",
    "gs_nb2.fit(clean_train_content, y_train)\n",
    "print(gs_nb2.best_score_)\n",
    "gs_nb2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gs_nb2.score(clean_train_content,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gs_nb2.score(clean_test_content,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### vi) View Naive Bayes Multinomial using confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Confusion matrix with CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb1_predictions=gs_nb1.predict(clean_test_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb1_cm=confusion_matrix(y_test, nb1_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb1_cm_df = pd.DataFrame(nb1_cm, columns=['pred Iphone', 'pred Android'], index=['actual Iphone', 'actual Android'])\n",
    "nb1_cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, nb1_predictions).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"True Negatives: %s\" % tn)\n",
    "print(\"False Positives: %s\" % fp)\n",
    "print(\"False Negatives: %s\" % fn)\n",
    "print(\"True Positives: %s\" % tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Confusion matrix with TFIDVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb2_predictions=gs_nb2.predict(clean_test_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb2_cm=confusion_matrix(y_test, nb2_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nb2_cm_df = pd.DataFrame(nb2_cm, columns=['pred Iphone', 'pred Android'], index=['actual Iphone', 'actual Android'])\n",
    "nb2_cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, nb2_predictions).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"True Negatives: %s\" % tn)\n",
    "print(\"False Positives: %s\" % fp)\n",
    "print(\"False Negatives: %s\" % fn)\n",
    "print(\"True Positives: %s\" % tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "By using different Count and TFID vectorizer, we can see that the model gives different results. We will evaluate our 2 models with TFIDVectorizer. Using their accuracy and precision score. We will view the model's performance using ROC curve as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def compareStats(m1,m2,xtrain,ytrain,xtest,ytest):\n",
    "    m1.fit(xtrain, ytrain)\n",
    "    score1=round(m1.score(xtest, ytest),2)\n",
    "    predictions1=m1.predict(xtest)\n",
    "    m1_cm=confusion_matrix(ytest, predictions1)\n",
    "    tn1, fp1, fn1, tp1 = confusion_matrix(ytest, predictions1).ravel()\n",
    "    recall1=round((tp1/(tp1+fn1)),2)\n",
    "    precision1=round((tp1/(tp1+fp1)),2)\n",
    "    \n",
    "    m2.fit(xtrain, ytrain)\n",
    "    score2=round(m2.score(xtest, ytest),2)\n",
    "    predictions2=m2.predict(xtest)\n",
    "    m2_cm=confusion_matrix(ytest, predictions2)\n",
    "    tn2, fp2, fn2, tp2 = confusion_matrix(ytest, predictions2).ravel()\n",
    "    recall2=round((tp2/(tp2+fn2)),2)\n",
    "    precision2=round((tp2/(tp2+fp2)),2)\n",
    "    \n",
    "    print(\"Stats     | Logistic Regression | Multinomial |\")\n",
    "    print(\"================================================\")\n",
    "    print(\"Recall    |          \",recall1,\"     |  \",recall2,\"      |\" )\n",
    "    print(\"Precision |          \",precision1,\"      |  \",precision2,\"     |\" )\n",
    "    print(\"Score     |          \",score1,\"     |  \",score2,\"     |\" )\n",
    "    print(\"TP        |          \",tp1,\"      |  \",tp2,\"      |\" )\n",
    "    print(\"TN        |          \",tn1,\"      |  \",tn2,\"      |\" )\n",
    "    print(\"FP        |          \",fp1,\"       |  \",fp2,\"       |\" )\n",
    "    print(\"FN        |          \",fn1,\"       |  \",fn2,\"       |\" )\n",
    "    \n",
    "    \n",
    "compareStats(pipe2,pipe4,clean_train_content,y_train,clean_test_content,y_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations from comparing Model stats\n",
    "We can see from the stats that both models performed similarly. In our case, precision score is important as we want to accurately identify Android posts. we want to know what Android users comment about their android phones and implement the right features. If If we wrongly implement a feature that was commented by an Iphone user on their Iphone, it may cause design and sales issues. However in this case, our both models have only slight differences in our most scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a dataframe called pred_df that contains:\n",
    "# 1. The list of true values of our test set.\n",
    "# 2. The list of predicted probabilities based on our model.\n",
    "\n",
    "pred_proba = [i[1] for i in pipe.predict_proba(clean_test_content)]\n",
    "\n",
    "pred_df = pd.DataFrame({'true_values': y_test,\n",
    "                        'pred_probs':pred_proba})\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a dataframe called pred_df that contains:\n",
    "# 1. The list of true values of our test set.\n",
    "# 2. The list of predicted probabilities based on our model.\n",
    "\n",
    "pred_proba2 = [i[1] for i in pipe2.predict_proba(clean_test_content)]\n",
    "\n",
    "pred_df2 = pd.DataFrame({'true_values': y_test,\n",
    "                        'pred_probs':pred_proba2})\n",
    "pred_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(pred_df['true_values'], pred_df['pred_probs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(pred_df2['true_values'], pred_df2['pred_probs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure.\n",
    "plt.figure(figsize = (10,7))\n",
    "\n",
    "# Create threshold values. (Dashed red line in image.)\n",
    "thresholds = np.linspace(0, 1, 200)\n",
    "\n",
    "# Define function to calculate sensitivity. (True positive rate.)\n",
    "def TPR(df, true_col, pred_prob_col, threshold):\n",
    "    true_positive = df[(df[true_col] == 1) & (df[pred_prob_col] >= threshold)].shape[0]\n",
    "    false_negative = df[(df[true_col] == 1) & (df[pred_prob_col] < threshold)].shape[0]\n",
    "    return true_positive / (true_positive + false_negative)\n",
    "    \n",
    "\n",
    "# Define function to calculate 1 - specificity. (False positive rate.)\n",
    "def FPR(df, true_col, pred_prob_col, threshold):\n",
    "    true_negative = df[(df[true_col] == 0) & (df[pred_prob_col] <= threshold)].shape[0]\n",
    "    false_positive = df[(df[true_col] == 0) & (df[pred_prob_col] > threshold)].shape[0]\n",
    "    return 1 - (true_negative / (true_negative + false_positive))\n",
    "    \n",
    "# Calculate sensitivity & 1-specificity for each threshold between 0 and 1.\n",
    "tpr_values = [TPR(pred_df, 'true_values', 'pred_probs', prob) for prob in thresholds]\n",
    "fpr_values = [FPR(pred_df, 'true_values', 'pred_probs', prob) for prob in thresholds]\n",
    "\n",
    "tpr_values2 = [TPR(pred_df2, 'true_values', 'pred_probs', prob) for prob in thresholds]\n",
    "fpr_values2 = [FPR(pred_df2, 'true_values', 'pred_probs', prob) for prob in thresholds]\n",
    "\n",
    "# Plot ROC curve.\n",
    "plt.plot(fpr_values, # False Positive Rate on X-axis\n",
    "         tpr_values, # True Positive Rate on Y-axis\n",
    "         label='LR ROC Curve',\n",
    "        color='orange')\n",
    "\n",
    "plt.plot(fpr_values2, # False Positive Rate on X-axis\n",
    "         tpr_values2, # True Positive Rate on Y-axis\n",
    "         label='MN ROC Curve')\n",
    "\n",
    "# Plot baseline. (Perfect overlap between the two populations.)\n",
    "plt.plot(np.linspace(0, 1, 200),\n",
    "         np.linspace(0, 1, 200),\n",
    "         label='baseline',\n",
    "         linestyle='--')\n",
    "\n",
    "# Label axes.\n",
    "plt.title(f'ROC Curve with AUC = {round(roc_auc_score(pred_df[\"true_values\"], pred_df[\"pred_probs\"]),3)}', fontsize=22)\n",
    "plt.ylabel('Sensitivity', fontsize=18)\n",
    "plt.xlabel('1 - Specificity', fontsize=18)\n",
    "\n",
    "# Create legend.\n",
    "plt.legend(fontsize=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intepreting ROC curve\n",
    "The more area under a curve means better better separated our distributions our model give. When our ROC AUC is closer to 1, then our positive and negative populations are better separated which means the model is better. From this graph, we can see that Logistic Regression gives a much better curve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion and Recommendations\n",
    "- From the model stats and ROC AUC curve, both models perform similarly and with acceptable accuracy. \n",
    "- We can look at other models to see if they can do better than our current models.\n",
    "- To further build on this project, we can look at sentiment analysis on the 2 topics. We can also look at specific mobile phone features that has more positive sentiment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
